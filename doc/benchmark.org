* Benchmarks for wonko-client

** Conclusions
*Disruptor > No queue > ArrayBlockingQueue*
- Disruptor gives us more consistent, and lower latencies than the
  alternatives. With BlockingWaitStrategy, we have minimum CPU and GC
  impact too.
- ArrayBlockingQueue latency goes up with the request rate, whereas
  disruptor latency stays more or less the same.
- It is essential to have a queue in between to provide isolation
  between the app and wonko-client.
- For the average case (75th percentile), disruptor is 7 times faster
  that having no queue and 16 times faster than ArrayBlockingQueue.

** Experiments and raw results
*** final local run
**** graphs
#+CAPTION: Latency at the 75th percentile
[[./graphs/bench-75.png]]

#+CAPTION: Latency at the 99th percentile
[[./graphs/bench-99.png]]

#+CAPTION: Latency at the 99.9th percentile
[[./graphs/bench-999.png]]

**** raw data
| throttled-rate |  rps | queue type |    queue size | tp/worker-pool size | send-time-75 | send-time-99 | send-time-999 |
|----------------+------+------------+---------------+---------------------+--------------+--------------+---------------|
|           1000 |  790 | no queue   | no queue size |          no tp size |       218918 |       436503 |       1500570 |
|           2000 | 1577 | no queue   | no queue size |          no tp size |       183281 |       430739 |       1327142 |
|           3000 | 2390 | no queue   | no queue size |          no tp size |       165614 |       425220 |        628402 |
|           4000 | 3154 | no queue   | no queue size |          no tp size |       155046 |       432736 |        603133 |
|           5000 | 3925 | no queue   | no queue size |          no tp size |       147519 |       411302 |        578308 |
|           6000 | 4705 | no queue   | no queue size |          no tp size |       133585 |       403021 |        616903 |
|           7000 | 5522 | no queue   | no queue size |          no tp size |       130784 |       406090 |        587240 |
|           8000 | 6324 | no queue   | no queue size |          no tp size |       128729 |       402283 |        582235 |
|           9000 | 7025 | no queue   | no queue size |          no tp size |       125865 |       393799 |        570553 |
|          10000 | 7861 | no queue   | no queue size |          no tp size |       120432 |       375549 |        553506 |
|           1000 |  818 | abq        |            10 |                  10 |       132789 |       652386 |      90957502 |
|           2000 | 1586 | abq        |            10 |                  10 |       215052 |       382786 |        841668 |
|           3000 | 2347 | abq        |            10 |                  10 |       287626 |       435453 |        515789 |
|           4000 | 3173 | abq        |            10 |                  10 |       329291 |       517349 |        844533 |
|           5000 | 3947 | abq        |            10 |                  10 |       362102 |       558997 |        709204 |
|           6000 | 4719 | abq        |            10 |                  10 |       373525 |       589455 |        775250 |
|           7000 | 5492 | abq        |            10 |                  10 |       365901 |       592956 |       1385424 |
|           8000 | 6343 | abq        |            10 |                  10 |       376036 |       615315 |       1206779 |
|           9000 | 7175 | abq        |            10 |                  10 |       350081 |       597768 |       1132775 |
|          10000 | 7882 | abq        |            10 |                  10 |       368519 |       780635 |       1582547 |
|           1000 |  790 | abq        |          1000 |                  10 |       108754 |       247473 |       1441054 |
|           2000 | 1688 | abq        |          1000 |                  10 |       193194 |       371105 |        866118 |
|           3000 | 2392 | abq        |          1000 |                  10 |       279077 |       440539 |        518728 |
|           4000 | 3132 | abq        |          1000 |                  10 |       329337 |       473826 |        534200 |
|           5000 | 3945 | abq        |          1000 |                  10 |       350862 |       531219 |        755660 |
|           6000 | 4786 | abq        |          1000 |                  10 |       350139 |       538139 |        805637 |
|           7000 | 5725 | abq        |          1000 |                  10 |       338901 |       530397 |        832585 |
|           8000 | 6584 | abq        |          1000 |                  10 |       341661 |       583404 |       1440206 |
|           9000 | 7482 | abq        |          1000 |                  10 |       333979 |       596005 |       1014704 |
|          10000 | 8701 | abq        |          1000 |                  10 |       288031 |       579563 |       1791730 |
|           1000 |  821 | disruptor  |            16 |                   1 |        34163 |       180853 |       2566461 |
|           2000 | 1621 | disruptor  |            16 |                   1 |        26182 |      1188669 |       3819964 |
|           3000 | 1681 | disruptor  |            16 |                   1 |       306676 |    114133176 |     220244500 |
|           4000 | 1754 | disruptor  |            16 |                   1 |       669543 |    115430893 |     125258057 |
|           5000 | 2087 | disruptor  |            16 |                   1 |       632007 |    105219995 |     125864459 |
|           1000 |  859 | disruptor  |            16 |                  10 |        26199 |       322101 |        447783 |
|           2000 | 1715 | disruptor  |            16 |                  10 |        21343 |       281108 |        459190 |
|           3000 | 2610 | disruptor  |            16 |                  10 |        20333 |       271145 |        442025 |
|           4000 | 2984 | disruptor  |            16 |                  10 |        19786 |       322003 |     125176862 |
|           5000 | 4338 | disruptor  |            16 |                  10 |        19888 |       250376 |        424923 |
|           6000 | 5187 | disruptor  |            16 |                  10 |        19365 |       242185 |        409713 |
|           7000 | 6058 | disruptor  |            16 |                  10 |        18948 |       229679 |        409784 |
|           8000 | 6914 | disruptor  |            16 |                  10 |        18806 |       231710 |        378026 |
|           9000 | 3949 | disruptor  |            16 |                  10 |        25399 |       483460 |      21390596 |
|          10000 | 4969 | disruptor  |            16 |                  10 |        22290 |       580961 |      45067581 |
|           1000 |  860 | disruptor  |          1024 |                  10 |        27990 |       348977 |       1687146 |
|           2000 | 1716 | disruptor  |          1024 |                  10 |        21359 |       314136 |        560561 |
|           3000 | 2565 | disruptor  |          1024 |                  10 |        20000 |       263999 |        493905 |
|           4000 | 3437 | disruptor  |          1024 |                  10 |        19506 |       257469 |        421756 |
|           5000 | 4290 | disruptor  |          1024 |                  10 |        18816 |       246165 |        404475 |
|           6000 | 5121 | disruptor  |          1024 |                  10 |        18972 |       235026 |        395729 |
|           7000 | 6027 | disruptor  |          1024 |                  10 |        18361 |       221632 |        365592 |
|           8000 | 6845 | disruptor  |          1024 |                  10 |        17640 |       213254 |        382307 |
|           9000 | 7738 | disruptor  |          1024 |                  10 |        17521 |       209734 |        379694 |
|          10000 | 8539 | disruptor  |          1024 |                  10 |        17198 |       211804 |        378985 |

**** code used to run the above benchmarks
#+begin_src clojure
(for [n [1000 2000 3000 4000 5000]]
		     (do
		       (Thread/sleep 1000)
		       (metrics-init)
		       (reset! util/rejected-count 0)
		       (let [total-requests (* 5 n)
			     throttled-fn (throttler/throttle-fn #(stream :some-api-call-again {:status 200 :boo 3004 :sdfca 49595 :asdfasdf 99032 :asdf "Sdf"} 999999999) n :second)
			     st (System/currentTimeMillis)]
			 (doall
			  (pmap (fn [_] (throttled-fn))
				(range total-requests)))
			 (let [et (System/currentTimeMillis)
			       exec-s (/ (- et st) 1000.0)]
			   {:total-requests total-requests
			    :request-rate-per-second (long (/ total-requests exec-s))
			    :throttled-rate n
			    :rejected-count (long @util/rejected-count)
			    :send-sync-count (count (:values (bean (.getSnapshot d/send-sync-timer))))
			    :send-async-count (count (:values (bean (.getSnapshot d/send-sync-timer))))
			    :serialize-count (count (:values (bean (.getSnapshot kp/serialize-timer))))
			    :send-sync-time (select-keys (bean (.getSnapshot d/send-sync-timer)) [:median :75thPercentile :95thPercentile :99thPercentile :999thPercentile])
			    :send-async-time (select-keys (bean (.getSnapshot d/send-async-timer)) [:median :75thPercentile :95thPercentile :99thPercentile :999thPercentile])
			    :serialize-time (select-keys (bean (.getSnapshot kp/serialize-timer)) [:median :75thPercentile :95thPercentile :99thPercentile :999thPercentile])}))))
#+end_src

*** remote run
- will add numbers here when we do this.

*** local run
- JVM opts: ["-Xmx1g" "-Xms1g" "-server"]
- Number of calls per service request = 5
- Kafka config
 {"bootstrap.servers" "localhost:9092",
   "reconnect.backoff.ms" 50,
   "request.timeout.ms" 2,
   "retry.backoff.ms" 10,
   "linger.ms" 5,
   "timeout.ms" "10",
   "total.memory.bytes" (* 1024 1024 120),
   "metadata.fetch.timeout.ms" 10,
   "block.on.buffer.full" "false",
   "queue.enqueue.timeout.ms" 0,
   "compression.type" "gzip"}


| case            | submit rate (per s) | collector-rate | net submit-rate | wonko consume rate | con/prod ratio | queue size | tp size | Memory Impact (B) | CPU impact (%) | GC impact (%) |
|-----------------+---------------------+----------------+-----------------+--------------------+----------------+------------+---------+-------------------+----------------+---------------|
|                 |                     |            <r> |          #ERROR |                <r> | #ERROR         |        <r> |     <r> |               <r> |            <r> |               |
| nothing         |                   0 |              0 |               0 |                  0 | 0/0            |          - |       - |        95,068,224 |              0 |             0 |
| baseline (0ms)  |                   0 |              0 |               0 |                  0 | 0/0            |         10 |      10 |       110,196,776 |            2.0 |             0 |
| baseline (10ms) |                   0 |              0 |               0 |                  0 | 0/0            |         10 |      10 |       117,417,896 |            2.5 |             0 |
| with metrics    |                1000 |           2000 |            7000 |               6200 | 88.571429      |         10 |      10 |       423,000,000 |            8.5 |             0 |
| with metrics    |                2000 |           2000 |           12000 |              10300 | 85.833333      |         10 |      10 |       403,000,000 |           12.0 |               |
| with metrics    |                5000 |           2000 |           27000 |              13600 | 50.370370      |         10 |      10 |       406,000,000 |           14.0 |               |
| with metrics    |               10000 |           2000 |           52000 |              13600 | 26.153846      |         10 |      10 |       422,000,000 |           14.0 |               |
#+TBLFM: $4=($2*5)+$3::$6=(100*$5/$4)

**** commands used to run
#+begin_src clojure
;;warmup
(run true {:service-latency-ms 0
           :total-requests 50000
           :request-rate 1000
           :collector-interval-ms 1
           :collector-metrics-count 1000})

;; nothing
(run false {:service-latency-ms 0
           :total-requests 100
           :request-rate 10
           :collector-interval-ms 1
           :collector-metrics-count 1 })

;; baseline 0
(run false {:service-latency-ms 0
           :total-requests 10000
           :request-rate 1000
           :collector-interval-ms 1
           :collector-metrics-count 1000})

;; baseline 10
(run false {:service-latency-ms 10
           :total-requests 10000
           :request-rate 1000
           :collector-interval-ms 1
           :collector-metrics-count 1000})

;; with metrics at 1000rps
(run true {:service-latency-ms 10
           :total-requests 30000
           :request-rate 1000
           :collector-interval-ms 1000
           :collector-metrics-count 2000})

;; with metrics at 2000rps
(run true {:service-latency-ms 10
           :total-requests 60000
           :request-rate 2000
           :collector-interval-ms 1000
           :collector-metrics-count 2000})

;; with metrics at 5000rps
(run true {:service-latency-ms 0
           :total-requests 150000
           :request-rate 5000
           :collector-interval-ms 1000
           :collector-metrics-count 2000})

;; with metrics at 10000rps
(run true {:service-latency-ms 10
           :total-requests 300000
           :request-rate 15000
           :collector-interval-ms 1000
           :collector-metrics-count 2000})

#+end_src

*** local run version 2
Measuring send-sync and async times
**** measurements
| actual-request-rate | total-requests | throttled-rate | rejected-count | ast-999thPercentile | st-999thPercentile | st-median | st-75thPercentile | st-95thPercentile | st-99thPercentile | ast-median | ast-75thPercentile | ast-95thPercentile | ast-99thPercentile |
|---------------------+----------------+----------------+----------------+---------------------+--------------------+-----------+-------------------+-------------------+-------------------+------------+--------------------+--------------------+--------------------|
|                1645 |          10000 |           2000 |              0 |            592061.0 |           224851.0 |   52263.0 |           59644.0 |          139049.0 |          176341.0 |   204620.0 |           304276.0 |           412180.0 |           490408.0 |
|                2468 |          15000 |           3000 |              0 |            685714.0 |           190222.0 |   51775.0 |           57779.0 |          123107.0 |          167050.0 |   284585.0 |           426633.0 |           549806.0 |           609387.0 |
|                3278 |          20000 |           4000 |              0 |            887018.0 |           183955.0 |   51701.0 |           57402.0 |          107337.0 |          154336.0 |   340807.0 |           487466.0 |           633968.0 |           723875.0 |
|                4148 |          25000 |           5000 |              0 |            997566.0 |           211745.0 |   51385.0 |           56755.0 |          125644.0 |          161258.0 |   347007.0 |           494005.0 |           669176.0 |           811025.0 |
|                4970 |          30000 |           6000 |              0 |           1085657.0 |           239369.0 |   50214.0 |           55434.0 |          106049.0 |          166500.0 |   347853.0 |           508968.0 |           680257.0 |           855127.0 |
|                5810 |          35000 |           7000 |              0 |           1014315.0 |          1192795.0 |   49977.0 |           56164.0 |          123754.0 |          262995.0 |   330126.0 |           484050.0 |           685888.0 |           881378.0 |
|                6620 |          40000 |           8000 |              0 |           1747155.0 |           843696.0 |   49088.0 |           54430.0 |          109068.0 |          219006.0 |   368088.0 |           502889.0 |           705081.0 |           865689.0 |
|                4308 |          45000 |           9000 |              0 |           9868456.0 |          9792410.0 |   37505.0 |           48442.0 |           87083.0 |          285704.0 |   126117.0 |           214873.0 |           398697.0 |           656801.0 |
|                8338 |          50000 |          10000 |              0 |           1409603.0 |          1143992.0 |   48765.0 |           56200.0 |          170113.0 |          570600.0 |   270828.0 |           390935.0 |           641007.0 |           831266.0 |

**** test run code
#+begin_src clojure
(for [n [1000 2000 3000 4000 5000 6000 7000 8000 9000 10000]]
  (do
    (Thread/sleep 1000)
    (metrics-init)
    (reset! util/rejected-count 0)
    (let [total-requests (* 5 n)
	  throttled-fn (throttler/throttle-fn #(stream :some-api-call-again {:status 200 :boo 3004 :sdfca 49595 :asdfasdf 99032 :asdf "Sdf"} 999999999) n :second)
	  st (System/currentTimeMillis)]
      (doall
       (pmap (fn [_] (throttled-fn))
	     (range total-requests)))
      (let [et (System/currentTimeMillis)
	    exec-s (/ (- et st) 1000.0)]
	{:total-requests total-requests
	 :request-rate-per-second (long (/ total-requests exec-s))
	 :throttled-rate n
	 :rejected-count (long @util/rejected-count)
	 :send-sync-count (count (:values (bean (.getSnapshot send-sync-timer))))
	 :send-async-count (count (:values (bean (.getSnapshot send-sync-timer))))
	 :serialize-count (count (:values (bean (.getSnapshot kp/serialize-timer))))
	 :send-sync-time (select-keys (bean (.getSnapshot send-sync-timer)) [:median :75thPercentile :95thPercentile :99thPercentile :999thPercentile])
	 :send-async-time (select-keys (bean (.getSnapshot send-async-timer)) [:median :75thPercentile :95thPercentile :99thPercentile :999thPercentile])
	 :serialize-time (select-keys (bean (.getSnapshot kp/serialize-timer)) [:median :75thPercentile :95thPercentile :99thPercentile :999thPercentile])}))))
#+end_src

*** local run version 3
Ensure that there are no timeouts in kafka sending.
**** configs
#+begin_src clojure
(def without-timeouts-kafka-config
  {"bootstrap.servers" "localhost:9092",
   "linger.ms" 5,
   "total.memory.bytes" (* 1024 1024 120),
   "block.on.buffer.full" "true",
   "compression.type" "gzip"})

(defn init! []
  (init! "test"
         without-timeouts-kafka-config
         :thread-pool-size 10
         :queue-size 10
         :drop-on-reject? false))
#+end_src

*** disruptor wait strategy comparison

Notes:
- We'll go with BlockingWaitStrategy for wonko-client since it's the
  least risky of all, and most predictable in terms of CPU usage
- The next best strategy seems to be
  PhasedBackoffWaitStrategy/withLock with 1+1 config.
- CPU information is not useful because it includes production cost.
- SleepingWaitStrategy is extremely efficient (10x) but needs
  CPU. This could be used in scenarios where disruptor is a primary
  part of the application.

| rps  | strategy                    |       cpu (%) | config (μs) | latency at 99.9%ile (ns) |
|------+-----------------------------+---------------+-------------+--------------------------|
|      |                             |           <r> |             |                          |
| 4300 | BlockingWaitStrategy        |            18 |           - |                   404475 |
| -    | SleepingWaitStrategy        | (constant) 50 |           - |                    46065 |
| -    | TimeoutBlockingWaitStrategy |             - |           1 |                        - |
| -    | PhasedBackoffWaitStrategy   |            20 |       10+10 |                   601707 |
| -    | PhasedBackoffWaitStrategy   |            20 |      100+10 |                   730032 |
| -    | PhasedBackoffWaitStrategy   |            19 |         1+1 |                   540837 |
| 9600 | PhasedBackoffWaitStrategy   |            90 |     0.5+0.5 |                  1124498 |
| 8000 | BlockingWaitStrategy        |            90 |           - |                  1230104 |

* Meta
** What kind of services are we looking to benchmark wonko-client for?
- Low latency services like Furtive and Eccentrica, that get over 1000
  requests per second, where request probably monitors about 5
  metrics. Roughly a couple of streams, counters and gauges.

** What questions are we looking to answer?
- What will the latency impact be?
- What will the memory requirement/impact be for such a service?
- What will the CPU requirement/impact be?
- What will the Network i/o impact be?
- What is the process of tuning wonko-client for performance or
  resource optimization?
- What are the available knobs/configs to tune performance? Are they
  sufficient?
- How do we tune wonko-client's performance for daemon/collector like
  processes that send a bunch of metrics in brief spikes or batches?

** What environment and h/w should the benchmarks be run on?
Typically, a production like environment. 4G RAM, 4 cores sound like a
reasonable configuration to run on without spending too much. We'll
run a real kafka instance in a separate machine/vm to emulate
reality.
